<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Style Replica Test</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/contrib/auto-render.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.css"
    />

    <style>
      body {
        background-color: #1f2937;
        overflow: hidden;
        font-family: sans-serif;
        height: 100vh;
      }
      .editor {
        font-family: monospace;
      }
      #overlay-html-layer * {
        margin: 0;
        padding: 0;
        left: 0%;
        top: 0%;
        box-sizing: border-box;
        line-height: 1; /* Reset to 1, as the AI will adjust font size on the p elements */
      }
      .tab {
        @apply px-3 py-1 text-xs cursor-pointer text-gray-400 hover:text-white border-b-2 border-transparent;
      }
      .tab.active {
        @apply text-green-400 border-green-400 bg-gray-900;
      }
    </style>
  </head>
  <body class="flex flex-col h-screen text-white">
    <header
      class="bg-gray-900 p-2 flex justify-between items-center shadow border-b border-gray-800"
    >
      <h1 class="font-bold text-purple-400 tracking-wider">
        Replica Debug: Command Strategy
      </h1>
      <button
        id="fullscreen-btn"
        class="bg-gray-700 hover:bg-gray-600 p-2 rounded-lg transition text-gray-300"
        onclick="document.documentElement.requestFullscreen()"
      >
        Full Screen
      </button>
      <div class="flex items-center gap-2">
        <span id="ai-status" class="text-blue-400 text-xs font-mono hidden"
          >Processing...</span
        >
        <input
          type="number"
          id="loop-count"
          value="1"
          min="1"
          max="10"
          class="w-12 bg-gray-800 text-center text-sm border border-gray-700 rounded"
        />
        <button
          id="run-btn"
          class="bg-purple-600 hover:bg-purple-500 px-3 py-1 text-sm rounded"
        >
          Run
        </button>
      </div>
    </header>

    <main class="flex-1 flex overflow-hidden">
      <div class="w-1/2 flex flex-col bg-gray-800 relative overflow-hidden">
        <div class="overflow-hidden flex-1 relative">
          <div id="wrapper" class="bg-white text-black absolute inset-0">
            <canvas id="view-canvas" class="absolute inset-0"></canvas>
            <div id="overlay-html-layer" class="absolute inset-0"></div>
          </div>
        </div>
      </div>

      <div class="w-1/2 flex flex-col bg-gray-800">
        <div class="flex border-b border-gray-800 bg-gray-800">
          <button id="tab-html" class="tab active" onclick="setTab('html')">
            HTML
          </button>
          <button id="tab-prompt" class="tab" onclick="setTab('prompt')">
            Prompt Text
          </button>
          <button id="tab-payload" class="tab" onclick="setTab('payload')">
            Full Payload
          </button>
          <button id="tab-response" class="tab" onclick="setTab('response')">
            Response Log
          </button>
        </div>

        <div class="flex-1 w-full relative">
          <textarea
            id="debug-textarea"
            class="editor absolute inset-0 p-4 bg-gray-900 text-green-400 text-xs outline-none border-none resize-none"
          ></textarea>

          <div
            id="debug-log-view"
            class="absolute inset-0 p-4 bg-gray-900 text-white text-xs overflow-auto hidden"
          ></div>
        </div>
      </div>
    </main>

    <canvas id="target-canvas-ai" style="display: none"></canvas>
    <canvas id="render-canvas-ai" style="display: none"></canvas>

    <script type="module">
      const apiKey = "";
      const SAMPLE_URL = "https://lsparrish.github.io/sciconvert/sample.png";
      const TEST_ID = "div-test-block";
      const AI_SCALE = 2.0;
      let img; // Declare img globally to be accessible everywhere

      // Initial Content
      const INITIAL_HTML = `<div id="${TEST_ID}" style="position: absolute; left: 4.92%; top: 2.34%; width: 88.80%; height: 26.53%; background: rgba(255,255,255,0.7); padding: 0px; margin: 0px; "> 
<p>Journal of the British Interplanetary Society, Vol. 36, pp. 115-128, 1983.</p>

<p>ORBITAL RING SYSTEMS AND JACOB'S LADDERS - II</p>

<p>PAUL BIRCH*</p>
<p>45, Brownville Road, Heaton Moor, Stockport, England.</p>

<p>A method of transferring payloads into space without using rockets has been presented in Part I, in which massive
rings encircle the globe in a low orbit supporting stationary 'sky-hooks,' from which cables hang down to any point on
the Earth's surface. Vehicles can climb up these 'ladders' into orbit, or can accelerate along the rings. The structure and
deployment of such Orbital Ring Systems is examined and their varied uses considered; several scenarios are considered
and shown to be economically feasible and beneficial.</p></div>`;

      // State
      const state = {
        history: [],
        aiLog: [],
        debug: {
          html: "",
          prompt: "// No prompt yet",
          payload: "// No request payload yet",
        },
        currTab: "html",
        targetAI: document.getElementById("target-canvas-ai"),
        renderAI: document.getElementById("render-canvas-ai"),
        viewCanvas: document.getElementById("view-canvas"),
        viewCtx: null, // Context initialized in img.onload

        promptTemplate: `Analyze visual differences. Target has RED BORDER. Render has RED BORDER.
Goal: Issue commands to align Render to Target.

COMMANDS (Array of objects):
- Move Actions: "moveUp", "moveDown", "moveLeft", "moveRight"
- Size Actions: "grow", "shrink"
- Font Settings: "setFontFamily" (Value: CSS font-family string), "setFontWeight" (Value: "bold", "normal", or number), "setFontSize" (Value: coefficient)
- Coefficient: 0.10 (tiny) to 5.00 (huge). 1.00 ~= 1em for size.

INPUT:
History Scores: {{history}}
Structure (IDs, Text, Current Styles): 
{{structure}}

INSTRUCTIONS:
Return JSON object { "element-id": [ { "action": "moveUp", "coefficient": 0.50 } ] }
Always use 2 decimal points (hundredths) for precision for coefficients.
For font actions, provide the string or number value directly (no coefficient).
Only include elements needing change. Use the "currentStyles" in the structure to inform your decision.`,
      };

      const els = {
        wrapper: document.getElementById("wrapper"),
        layer: document.getElementById("overlay-html-layer"),
        output: document.getElementById("debug-textarea"),
        logView: document.getElementById("debug-log-view"),
        status: document.getElementById("ai-status"),
        runBtn: document.getElementById("run-btn"),
        loopInput: document.getElementById("loop-count"),
      };

      // --- UI Logic ---
      window.setTab = (t) => {
        state.currTab = t;

        // Hide/Show correct output element
        const isTextTab = t === "html" || t === "prompt" || t === "payload";
        els.output.classList.toggle("hidden", !isTextTab);
        els.logView.classList.toggle("hidden", isTextTab);

        // Add check to hide textarea when showing prompt/payload with HTML content
        const isHtmlContent = t === "prompt" || t === "payload";
        // The output textarea should only be visible for the editable 'html' tab
        els.output.classList.toggle("hidden", isHtmlContent);
        // The log view is used for both 'response' and the HTML content of 'prompt'/'payload'
        els.logView.classList.toggle(
          "hidden",
          !isHtmlContent && t !== "response",
        );

        // Update active tab buttons
        document.querySelectorAll(".tab").forEach((el) => {
          el.classList.remove("active");
          if (el.id.includes(t)) {
            el.classList.add("active");
          }
        });

        // Update content
        if (t === "html") {
          // Read the current live state from the DOM, format it, and push it to the textarea
          // This ensures the editor reflects the current styled HTML
          els.output.value = els.layer.innerHTML
            .replace(/<\/div>/g, "</div>\n")
            .replace(/<br>/g, "<br>\n");
        } else if (t === "response") {
          // Render the AI Log (HTML content)
          let logContent = state.aiLog
            .map((entry, i) => {
              const status = entry.success ? "SUCCESS" : "ERROR";
              const rawResponse = entry.response
                ? JSON.stringify(entry.response, null, 2)
                : entry.response;
              return `<div style="border-bottom: 1px solid #374151; padding-bottom: 1rem; margin-bottom: 1rem;">
                        <h4 style="font-weight: bold; color: ${entry.success ? "#9be658" : "#ef4444"};">--- Iteration ${entry.iter} (${entry.timestamp}) - ${status} ---</h4>
                        <div style="margin-top: 0.5rem; display: flex; gap: 1rem; align-items: flex-start; justify-content: space-around;">
                            <div style="text-align: center; font-family: monospace;">
                                Target:<br>
                                <img src="data:image/png;base64,${entry.request.images.target}" style="width: 150px; height: auto; border: 2px solid #f97316; margin: 4px;" alt="Target Image Thumbnail" />
                            </div>
                            <div style="text-align: center; font-family: monospace;">
                                Render:<br>
                                <img src="data:image/png;base64,${entry.request.images.render}" style="width: 150px; height: auto; border: 2px solid #3b82f6; margin: 4px;" alt="Render Image Thumbnail" />
                            </div>
                        </div>
                        <pre style="white-space: pre-wrap; margin-top: 0.5rem; background: #111827; padding: 0.5rem; border-radius: 4px; color: #d1d5db; font-size: 0.75rem;">Request Structure: ${JSON.stringify(entry.request.structure, null, 2).substring(0, 300) + "..."}</pre>
                        <pre style="white-space: pre-wrap; background: #111827; padding: 0.5rem; border-radius: 4px; color: #9be658; font-size: 0.75rem;">Raw Response: ${rawResponse}</pre>
                    </div>`;
            })
            .join("");
          els.logView.innerHTML =
            logContent ||
            "<div style='font-family: monospace;'>// No AI responses yet.</div>";
        } else if (t === "prompt" || t === "payload") {
          // Inject HTML content (which includes the thumbnails) into the log view
          els.logView.innerHTML = state.debug[t];
        }
      };

      els.output.addEventListener("input", () => {
        if (state.currTab === "html") {
          // User input updates the live DOM for immediate preview
          els.layer.innerHTML = els.output.value;
          renderMathInElement(els.layer, {
            delimiters: [{ left: "$$", right: "$$", display: true }],
          });
        }
      });

      // --- Core Logic ---

      function getStructure(divId) {
        const div = document.getElementById(divId);
        if (!div) return [];
        // Ensure IDs
        Array.from(div.children).forEach((el, i) => {
          if (!el.id) el.id = `blk-${Date.now()}-${i}`;
        });

        return Array.from(div.children)
          .filter((el) => el.innerText.trim().length > 0)
          .map((el) => {
            // Get current styles for the AI to reference
            const computedStyle = window.getComputedStyle(el);

            return {
              id: el.id,
              tag: el.tagName.toLowerCase(),
              text: el.innerText.substring(0, 30),
              currentStyles: {
                top: el.style.top || "0em",
                left: el.style.left || "0em",
                fontSize: el.style.fontSize || "1.0em",
                // New font properties from inline style or computed style
                fontFamily: el.style.fontFamily || computedStyle.fontFamily,
                fontWeight: el.style.fontWeight || computedStyle.fontWeight,
              },
            };
          });
      }

      function applyCommands(updates) {
        let count = 0;
        for (const [id, cmds] of Object.entries(updates)) {
          const el = document.getElementById(id);
          // Crucial: The element must exist in the live DOM
          if (!el || !Array.isArray(cmds)) continue;

          el.style.position = "relative";
          let top = parseFloat(el.style.top) || 0;
          let left = parseFloat(el.style.left) || 0;
          let size = parseFloat(el.style.fontSize) || 1.0;

          cmds.forEach((c) => {
            const v = parseFloat(c.coefficient) || 0;

            // Movement and Sizing actions
            if (c.action === "moveUp") top -= v;
            if (c.action === "moveDown") top += v;
            if (c.action === "moveLeft") left -= v;
            if (c.action === "moveRight") left += v;
            if (c.action === "grow") size += v;
            if (c.action === "shrink") size = Math.max(0.1, size - v);

            // Font actions (using value/string instead of coefficient)
            if (c.action === "setFontFamily" && c.value) {
              el.style.fontFamily = String(c.value);
            }
            if (c.action === "setFontWeight" && c.value) {
              // Ensure value is a valid string (like 'bold', 'normal') or a number (like 700)
              el.style.fontWeight = String(c.value);
            }
            // setFontSize is handled by grow/shrink, but we can add a direct setter for completeness
            if (c.action === "setFontSize" && c.value) {
              const s = parseFloat(c.value);
              if (!isNaN(s)) {
                el.style.fontSize = s.toFixed(2) + "em";
              }
            }
          });

          // Apply the calculated styles to the live DOM element
          el.style.top = top.toFixed(2) + "em";
          el.style.left = left.toFixed(2) + "em";
          el.style.fontSize = size.toFixed(2) + "em";
          count++;
        }
        return count;
      }

      /**
       * Combines the static target image (bg) and the pre-cropped HTML render into one canvas.
       * The captured HTML content is now already aligned to the target's (0, 0) due to
       * html2canvas options.
       * * @param {HTMLCanvasElement} targetCan - The cropped, fixed target image.
       * @param {HTMLCanvasElement} htmlCan - The transparent, captured HTML content (pre-cropped).
       * @returns {HTMLCanvasElement} The final, combined render canvas (using state.renderAI).
       */
      function createCombinedRender(targetCan, htmlCan) {
        const rendCan = state.renderAI;
        rendCan.width = targetCan.width;
        rendCan.height = targetCan.height;
        const rendCtx = rendCan.getContext("2d");

        // 1. Draw the static target image (background).
        rendCtx.drawImage(targetCan, 0, 0);

        // 2. Overlay the captured HTML content, which is now ALIGNED to (0, 0)
        // due to the html2canvas fix.
        rendCtx.drawImage(htmlCan, 0, 0);

        return rendCan;
      }

      async function fetchWithBackoff(parts) {
        for (let attempt = 0; attempt < 5; attempt++) {
          try {
            const resp = await fetch(
              `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`,
              {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ contents: [{ role: "user", parts }] }),
              },
            );

            if (!resp.ok && resp.status === 429) {
              const delay = Math.pow(2, attempt) * 1000 + Math.random() * 1000;
              await new Promise((res) => setTimeout(res, delay));
              continue;
            }
            if (!resp.ok)
              throw new Error(
                `API error: ${resp.status} - ${await resp.text()}`,
              );

            const json = await resp.json();
            return json.candidates?.[0]?.content?.parts?.[0]?.text;
          } catch (e) {
            if (attempt === 4) throw e;
            const delay = Math.pow(2, attempt) * 1000 + Math.random() * 1000;
            await new Promise((res) => setTimeout(res, delay));
          }
        }
        throw new Error("API call failed after multiple retries.");
      }

      // --- Helpers ---

      function cropAndScale(rect, scale, source) {
        const c = document.createElement("canvas");
        c.width = rect.w * scale;
        c.height = rect.h * scale;
        const ctx = c.getContext("2d");
        ctx.fillStyle = "#fff";
        ctx.fillRect(0, 0, c.width, c.height);

        ctx.drawImage(
          source,
          rect.x,
          rect.y,
          rect.w,
          rect.h,
          0,
          0,
          c.width,
          c.height,
        );
        return c;
      }

      function addBorder(canvas) {
        const c = document.createElement("canvas");
        c.width = canvas.width;
        c.height = canvas.height;
        const ctx = c.getContext("2d");
        ctx.drawImage(canvas, 0, 0);
        ctx.strokeStyle = "red";
        ctx.lineWidth = 2;
        ctx.strokeRect(0, 0, c.width, c.height);
        return c;
      }

      function getRect(divId) {
        const div = document.getElementById(divId);
        if (!div) return null;
        const cw = state.viewCanvas.width,
          ch = state.viewCanvas.height;
        return {
          x: (parseFloat(div.style.left) / 100) * cw,
          y: (parseFloat(div.style.top) / 100) * ch,
          w: (parseFloat(div.style.width) / 100) * cw,
          h: (parseFloat(div.style.height) / 100) * ch,
        };
      }

      async function getDiff(b64A, b64B) {
        return new Promise((r) => {
          const i1 = new Image(),
            i2 = new Image();
          let c = 0;
          const onload = () => {
            if (++c === 2) diff();
          };
          i1.onload = onload;
          i2.onload = onload;
          i1.src = "data:image/png;base64," + b64A;
          i2.src = "data:image/png;base64," + b64B;
          function diff() {
            const cv = document.createElement("canvas");
            cv.width = i1.width;
            cv.height = i1.height;
            const cx = cv.getContext("2d");
            cx.drawImage(i1, 0, 0);
            const d1 = cx.getImageData(0, 0, cv.width, cv.height).data;
            cx.clearRect(0, 0, cv.width, cv.height);
            cx.drawImage(i2, 0, 0);
            const d2 = cx.getImageData(0, 0, cv.width, cv.height).data;
            let sum = 0;
            for (let k = 0; k < d1.length; k += 4)
              sum +=
                Math.abs(d1[k] - d2[k]) +
                Math.abs(d1[k + 1] - d2[k + 1]) +
                Math.abs(d1[k + 2] - d2[k + 2]);
            r(sum / (i1.width * i1.height * 765));
          }
        });
      }

      function preparePayloadAndPrompt(targetCanvas, renderCanvas, iterLabel) {
        const divEl = document.getElementById(TEST_ID);
        if (!divEl) {
          console.error("div-test-block not found in DOM.");
          return { parts: [{ text: "// Error: Content not found" }] };
        }

        const struct = getStructure(TEST_ID);
        let promptTemplateText = state.promptTemplate
          .replace("{{history}}", state.history.join(", "))
          .replace("{{structure}}", JSON.stringify(struct, null, 2));

        // --- Thumbnail Generation ---
        const borderedTarget = addBorder(targetCanvas);
        const borderedRender = addBorder(renderCanvas);

        const targetBase64 = borderedTarget.toDataURL().split(",")[1];
        const renderBase64 = borderedRender.toDataURL().split(",")[1];

        const targetThumb = `<img src="data:image/png;base64,${targetBase64}" style="width: 150px; height: auto; border: 2px solid #f97316; margin: 4px; display: block;" alt="Target Image Thumbnail" />`;
        const renderThumb = `<img src="data:image/png;base64,${renderBase64}" style="width: 150px; height: auto; border: 2px solid #3b82f6; margin: 4px; display: block;" alt="Render Image Thumbnail" />`;

        // 1. Prepare Prompt Text (HTML content with images)
        // Replace the opening line with the visual representation
        let visualPrompt =
          `
    // --- Visual Input ---
    <div style="display: flex; gap: 20px; margin-bottom: 10px;">
        <div>Target (Red Border): ${targetThumb}</div>
        <div>Render (Red Border): ${renderThumb}</div>
    </div>
    ------------------------\n\n` + promptTemplateText;

        state.debug.prompt = visualPrompt;

        // 2. Prepare Payload (Bordered images)
        const parts = [{ text: promptTemplateText }]; // Send the CLEAN text prompt to the AI

        const imageBase64s = [targetBase64, renderBase64];

        // Add to parts for API call
        imageBase64s.forEach((b64) => {
          parts.push({ inlineData: { mimeType: "image/png", data: b64 } });
        });

        const payloadObj = {
          iter: iterLabel || "Initial",
          // score is hard to calculate here without full iteration, so we skip it for init
          prompt: promptTemplateText, // Use clean text prompt in the JSON payload object
          structure: struct,
          images: {
            target: imageBase64s[0],
            render: imageBase64s[1],
          },
        };

        // 3. Prepare Debug Payload View (HTML content with images and truncated base64)
        const displayPayload = {
          ...payloadObj,
          images: {
            target: payloadObj.images.target.substring(0, 30) + "...",
            render: payloadObj.images.render.substring(0, 30) + "...",
          },
        };

        const payloadJsonText = JSON.stringify(displayPayload, null, 2);

        // Add the image visualization to the payload view
        state.debug.payload = `
    // --- Visual Input ---
    <div style="display: flex; gap: 20px; margin-bottom: 10px;">
        <div>Target: ${targetThumb}</div>
        <div>Render: ${renderThumb}</div>
    </div>
    ------------------------
    <pre style="white-space: pre-wrap; font-family: monospace; color: #d1d5db;">${payloadJsonText}</pre>
        `;

        return { parts, payloadObj };
      }

      /**
       * Unifies the logic for capturing the fixed Target, capturing the current Render state,
       * and generating the payload/prompt for the AI.
       * @param {HTMLImageElement} originalImage The full background image (img).
       * @param {boolean} isInitialRun Whether to set the fixed state.targetAI image.
       * @param {string} iterLabel The current iteration label for logging/debugging.
       * @returns {Promise<void>}
       */
      async function updateAIImagesAndPayload(
        originalImage,
        isInitialRun,
        iterLabel,
      ) {
        const divEl = document.getElementById(TEST_ID);
        if (!divEl) {
          console.error("div-test-block not found in DOM.");
          return;
        }
        const rect = getRect(TEST_ID);

        // 1. INITIAL TARGET AI SETUP (Only run once)
        if (isInitialRun) {
          const srcCan = cropAndScale(rect, AI_SCALE, originalImage);
          state.targetAI.width = srcCan.width;
          state.targetAI.height = srcCan.height;
          state.targetAI.getContext("2d").drawImage(srcCan, 0, 0);
        }

        // 2. CAPTURE RENDER IMAGE
        // CRITICAL FIX: Use only scaled width/height, which causes html2canvas to capture the
        // content aligned to (0, 0) of the resulting canvas.
        const htmlLayerCan = await html2canvas(divEl, {
          scale: AI_SCALE,
          backgroundColor: null,
          width: rect.w * AI_SCALE,
          height: rect.h * AI_SCALE,
        });

        // B. Combine Target background and captured HTML into the final Render canvas
        const renderCan = createCombinedRender(state.targetAI, htmlLayerCan);

        // 3. Generate the prompt and payload
        preparePayloadAndPrompt(state.targetAI, renderCan, iterLabel);
      }

      // --- Main Loop ---

      async function runIteration(iter) {
        const divEl = document.getElementById(TEST_ID);
        // CRITICAL: Prevent the run if divEl is missing due to a previous DOM manipulation error
        if (!divEl) {
          console.error("div-test-block not found in DOM. Skipping iteration.");
          return;
        }

        els.status.textContent = `${iter} Capturing...`;
        els.status.style.display = "inline";

        // 1. CAPTURE AND PREPARE IMAGES/PAYLOAD (using the unified function)
        await updateAIImagesAndPayload(img, false, iter);

        const rect = getRect(TEST_ID);
        const srcCan = state.targetAI;
        const rendCan = state.renderAI;

        // 2. Update the User Viewer (Display the final AI-processed image)

        // A. Redraw the full background image (img) onto the viewCanvas
        state.viewCtx.drawImage(
          img,
          0,
          0,
          state.viewCanvas.width,
          state.viewCanvas.height,
        );

        // B. Draw the combined, AI-scaled render image (rendCan)
        // back onto the viewer, scaled down and positioned correctly.
        state.viewCtx.drawImage(
          rendCan,
          0,
          0,
          rendCan.width,
          rendCan.height, // Source: the full rendCan (at AI_SCALE)
          rect.x,
          rect.y,
          rect.w,
          rect.h, // Destination: back to the 1x rect location
        );

        // 3. Diff & History
        const srcB64 = srcCan.toDataURL().split(",")[1];
        const rendB64 = rendCan.toDataURL().split(",")[1];
        const score = await getDiff(srcB64, rendB64);
        state.history.push((score * 100).toFixed(2) + "%");

        // 4. Prompt & Payload (Retrieve the pre-generated payload)
        const { parts, payloadObj } = preparePayloadAndPrompt(
          srcCan,
          rendCan,
          iter,
        );
        // We can inject the score here for the payload/log
        payloadObj.score = (score * 100).toFixed(2) + "%";

        if (state.currTab !== "html") window.setTab(state.currTab); // refresh view

        // 5. AI Call
        els.status.textContent = `${iter} Thinking...`;
        let logEntry = {
          iter,
          success: false,
          request: payloadObj,
          response: "Error/No response",
          timestamp: new Date().toLocaleTimeString(),
        };

        try {
          const resultJsonStr = await fetchWithBackoff(parts);

          if (!resultJsonStr) {
            throw new Error("Empty response from AI.");
          }

          const jsonMatch = resultJsonStr.match(/\{[\s\S]*\}/);
          const updates = JSON.parse(jsonMatch ? jsonMatch[0] : "{}");

          logEntry.response = updates;
          logEntry.success = true;

          const n = applyCommands(updates);
          console.log(
            `Applied ${n} updates. Score: ${(score * 100).toFixed(2)}%`,
          );

          // Update the editor's content after successful style application
          els.output.value = els.layer.innerHTML
            .replace(/<\/div>/g, "</div>\n")
            .replace(/<br>/g, "<br>\n");
          if (state.currTab === "html") {
            // Rerun setTab to refresh the textarea's visible content
            window.setTab("html");
          }
        } catch (e) {
          logEntry.response = `Error: ${e.message}`;
          console.error(e);
        } finally {
          state.aiLog.unshift(logEntry);
          if (state.currTab === "response") window.setTab("response");

          // --- Prepare Payload for the NEXT iteration ---
          // Call the unified function to prepare the next target/render images for the AI
          await updateAIImagesAndPayload(
            img,
            false,
            `Pre-Run ${state.aiLog.length + 1}`,
          );
        }
      }

      els.runBtn.onclick = async () => {
        els.runBtn.disabled = true;
        state.history = [];
        const max = parseInt(els.loopInput.value);

        // Save current HTML state before running (already in els.output.value)

        for (let i = 1; i <= max; i++) await runIteration(`Run ${i}/${max}`);

        // Restore HTML layer for editing (using the final state saved in the editor)
        els.layer.innerHTML = els.output.value;

        // Redraw the original full image to the viewCanvas background
        state.viewCtx.drawImage(
          img,
          0,
          0,
          state.viewCanvas.width,
          state.viewCanvas.height,
        );

        els.status.style.display = "none";
        els.runBtn.disabled = false;
        window.setTab("html"); // show final HTML result
      };

      // Initialization: Initial HTML is loaded from constant into editor and live DOM
      els.output.value = INITIAL_HTML.replace(/<\/div>/g, "</div>\n").replace(
        /<br>/g,
        "<br>\n",
      );
      els.layer.innerHTML = INITIAL_HTML;
      const divEl = document.getElementById(TEST_ID);

      window.setTab("html");
      renderMathInElement(els.layer, {
        delimiters: [{ left: "$$", right: "$$", display: true }],
      });

      img = new Image(); // Assign to the global img variable
      img.crossOrigin = "anonymous";
      img.onload = async () => {
        // 1. Set the size of the *container* and the *viewer canvas*
        state.viewCanvas.width = img.width;
        state.viewCanvas.height = img.height;
        els.wrapper.style.width = state.viewCanvas.width + "px";
        els.wrapper.style.height = state.viewCanvas.height + "px";
        // 2. Initialize Context (Fix for TypeError)
        state.viewCtx = state.viewCanvas.getContext("2d");

        // 3. Draw the full image onto the viewer canvas
        state.viewCtx.drawImage(
          img,
          0,
          0,
          state.viewCanvas.width,
          state.viewCanvas.height,
        );

        // 4. Run the unified setup function (Setting isInitialRun to true)
        await updateAIImagesAndPayload(img, true, "Initial");
      };
      img.onerror = () => {
        console.error("Image failed to load");
      };
      img.src = SAMPLE_URL;
    </script>
  </body>
</html>
