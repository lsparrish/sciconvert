<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Style Replica Test</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/contrib/auto-render.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.css"
    />

    <style>
      body {
        background-color: #1f2937;
        overflow: hidden;
        font-family: sans-serif;
        height: 100vh;
      }
      .editor {
        font-family: monospace;
      }
      #overlay-html-layer {
        z-index: 0; /* Send HTML to back so it is hidden behind the canvas */
      }
      #overlay-html-layer * {
        margin: 0;
        padding: 0;
        left: 0%;
        top: 0%;
        box-sizing: border-box;
        line-height: 1; /* Reset to 1, as the AI will adjust font size on the p elements */
      }
      #view-canvas {
        z-index: 10; /* Bring canvas to front to display the AI's actual view */
      }
      .tab {
        @apply px-3 py-1 text-xs cursor-pointer text-gray-400 hover:text-white border-b-2 border-transparent;
      }
      .tab.active {
        @apply text-green-400 border-green-400 bg-gray-900;
      }
      .base64-toggle-span {
        cursor: pointer;
        color: #8b5cf6; /* purple-500 */
        text-decoration: underline;
        font-family: monospace;
        font-size: 0.8em;
      }
      .base64-full {
        display: none;
        font-size: 0.6em;
        word-break: break-all;
        user-select: all;
        color: #fca311; /* yellow/orange */
        background-color: #111827;
        padding: 4px;
        border-radius: 4px;
        margin-top: 4px;
      }
      .base64-container {
        display: flex;
        flex-direction: column;
        align-items: flex-start;
      }
      .image-thumbnail-payload {
        width: 100px;
        height: auto;
        margin-top: 5px;
        border: 1px solid #4b5563; /* gray-600 */
        border-radius: 4px;
      }
    </style>
  </head>
  <body class="flex flex-col h-screen text-white">
    <header
      class="bg-gray-900 p-2 flex justify-between items-center shadow border-b border-gray-800"
    >
      <h1 class="font-bold text-purple-400 tracking-wider">
        Replica Debug: Visual Empiricism
      </h1>
      <button
        id="fullscreen-btn"
        class="bg-gray-700 hover:bg-gray-600 p-2 rounded-lg transition text-gray-300"
        onclick="document.documentElement.requestFullscreen()"
      >
        Full Screen
      </button>
      <div class="flex items-center gap-2">
        <span id="ai-status" class="text-blue-400 text-xs font-mono hidden"
          >Processing...</span
        >
        <input
          type="number"
          id="loop-count"
          value="1"
          min="1"
          max="10"
          class="w-12 bg-gray-800 text-center text-sm border border-gray-700 rounded"
        />
        <button
          id="run-btn"
          class="bg-purple-600 hover:bg-purple-500 px-3 py-1 text-sm rounded"
        >
          Run
        </button>
      </div>
    </header>

    <main class="flex-1 flex overflow-hidden">
      <div class="w-1/2 flex flex-col bg-gray-800 relative overflow-hidden">
        <div class="overflow-hidden flex-1 relative">
          <div id="wrapper" class="bg-white text-black absolute inset-0">
            <canvas id="view-canvas" class="absolute inset-0"></canvas>
            <div id="overlay-html-layer" class="absolute inset-0"></div>
          </div>
        </div>
      </div>

      <div class="w-1/2 flex flex-col bg-gray-800">
        <div class="flex border-b border-gray-800 bg-gray-800">
          <button id="tab-html" class="tab active" onclick="setTab('html')">
            HTML
          </button>
          <button id="tab-prompt" class="tab" onclick="setTab('prompt')">
            Prompt Text
          </button>
          <button id="tab-payload" class="tab" onclick="setTab('payload')">
            Full Payload
          </button>
          <button id="tab-response" class="tab" onclick="setTab('response')">
            Response Log
          </button>
        </div>

        <div class="flex-1 w-full relative">
          <textarea
            id="debug-textarea"
            class="editor absolute inset-0 p-4 bg-gray-900 text-green-400 text-xs outline-none border-none resize-none"
          ></textarea>

          <div
            id="debug-log-view"
            class="absolute inset-0 p-4 bg-gray-900 text-white text-xs overflow-auto hidden"
          ></div>
        </div>
      </div>
    </main>

    <canvas id="target-canvas-ai" style="display: none"></canvas>
    <canvas id="render-canvas-ai" style="display: none"></canvas>
    <!-- New hidden canvas for overlap detection -->
    <canvas id="overlap-canvas" style="display: none"></canvas>

    <script type="module">
      const apiKey = "";
      const SAMPLE_URL = "https://lsparrish.github.io/sciconvert/sample.png";
      const TEST_ID = "div-test-block";

      const DEFAULT_AI_SCALE = 0.5;
      const FINAL_AI_SCALE = 2.0;

      let currentRunScale = DEFAULT_AI_SCALE; // Variable to track the scale for the current run
      let img; // Declare img globally to be accessible everywhere

      // Initial Content
      const INITIAL_HTML = `<div id="${TEST_ID}" style="position: absolute; left: 4.92%; top: 2.34%; width: 88.80%; height: 26.53%; background: rgba(255,255,255,0.7); padding: 0px; margin: 0px; "> 
<p>Journal of the British Interplanetary Society, Vol. 36, pp. 115-128, 1983.</p>

<p>ORBITAL RING SYSTEMS AND JACOB'S LADDERS - II</p>

<p>PAUL BIRCH*</p>
<p>45, Brownville Road, Heaton Moor, Stockport, England.</p>

<p>A method of transferring payloads into space without using rockets has been presented in Part I, in which massive
rings encircle the globe in a low orbit supporting stationary 'sky-hooks,' from which cables hang down to any point on
the Earth's surface. Vehicles can climb up these 'ladders' into orbit, or can accelerate along the rings. The structure and
deployment of such Orbital Ring Systems is examined and their varied uses considered; several scenarios are considered
and shown to be economically feasible and beneficial.</p></div>`;

      // State
      const state = {
        // history: { score: string, commands: object, resultImage: base64String, structure: { elements, maxExtent } }
        history: [],
        aiLog: [],
        debug: {
          html: "// No HTML debug yet",
          prompt: "// No prompt yet",
          payload: "// No request payload yet",
        },
        currTab: "html",
        targetAI: document.getElementById("target-canvas-ai"),
        renderAI: document.getElementById("render-canvas-ai"),
        overlapCanvas: document.getElementById("overlap-canvas"), // Reference to the new overlap canvas
        viewCanvas: document.getElementById("view-canvas"),
        viewCtx: null, // Context initialized in img.onload
        MAX_VERTICAL_EM: 10.0, // Heuristic maximum vertical extent for the content box

        // Updated Template: Removed {{history_log}} as history is now provided via multi-part payload
        promptTemplate: `# ROLE
You are a Visual Layout Alignment Engine. Your goal is to achieve pixel-perfect superposition of elements in a "Current Render" (Blue Border) to match a "Target" (Red Border).

# OBJECTIVE
Analyze the provided structure and visual descriptions to issue JSON commands. 
Goal State: Maximize the overlap (intersection) between the Current Render and the Target. 
Success Metric: When elements overlap perfectly, they turn specific pixels BLUE. 
- Warning: Partial overlaps of wrong text also turn blue (False Positives). Ensure the *content* is logically aligned, not just the pixels.

# PHYSICS & COORDINATE SYSTEM
- Origin: Top-Left (0,0).
- Size vs. Position: "grow" expands the element outwards. Depending on the anchor point, growing an element may push its center point to the right and down.
- Heuristic: Align the TOP-LEFT corner of the first letter first (Position), then adjust the bounding box (Size/Font).

# AVAILABLE COMMANDS
1. Move: "moveUp", "moveDown", "moveLeft", "moveRight" (Coefficient: 0.10 to 5.00).
2. Size: "grow", "shrink" (Coefficient: 0.10 to 5.00).
3. Font: 
   - "setFontFamily" (Value: string)
   - "setFontWeight" (Value: "bold", "normal", or number)
   - "setFontSize" (Value: coefficient)

# ANALYSIS STEPS (Internal Monologue)
Before generating JSON, assess the following for each element:
1. **Delta Check:** precise difference in X/Y coordinates and Dimensions compared to Target.
2. **History Check:** Look at \`Last Step Commands\`. Did the previous move overshoot? If yes, apply a smaller coefficient in the opposite direction (Damping).
3. **Loop Detection:** If the element is oscillating between two states across frames, reduce coefficient magnitude by 50%.
4. **Ordering:** Prioritize Position (Move) -> Size -> Font Styles.
5. **Accuracy:** If the elements that overlap are not the same text, movement (including resizing of other text) is needed.

# OUTPUT RULES
- Return ONLY a raw JSON object. No markdown formatting, no conversational text.
- Precision: Coefficients must use 2 decimal places (e.g., 0.50).
- Efficiency: Only include elements that require changes.

# INPUT DATA
{{structure}}

# RESPONSE FORMAT
{
  "element-id": [
    { "action": "moveUp", "coefficient": 0.50 },
    { "action": "setFontWeight", "value": "bold" }
  ]
}`,
      };

      const els = {
        wrapper: document.getElementById("wrapper"),
        layer: document.getElementById("overlay-html-layer"),
        output: document.getElementById("debug-textarea"),
        logView: document.getElementById("debug-log-view"),
        status: document.getElementById("ai-status"),
        runBtn: document.getElementById("run-btn"),
        loopInput: document.getElementById("loop-count"),
      };

      // --- Global Helper for Toggling Base64 ---
      window.toggleBase64 = (id) => {
        const fullEl = document.getElementById(id);
        if (fullEl) {
          fullEl.style.display =
            fullEl.style.display === "block" ? "none" : "block";
        }
      };
      // --- UI Logic ---
      window.setTab = (t) => {
        state.currTab = t;

        // Hide/Show correct output element
        const isTextTab = t === "html" || t === "prompt" || t === "payload";
        els.output.classList.toggle("hidden", !isTextTab);
        els.logView.classList.toggle("hidden", isTextTab);

        const isHtmlContent = t === "prompt" || t === "payload";
        els.output.classList.toggle("hidden", isHtmlContent);
        els.logView.classList.toggle(
          "hidden",
          !isHtmlContent && t !== "response",
        );

        document.querySelectorAll(".tab").forEach((el) => {
          el.classList.remove("active");
          if (el.id.includes(t)) {
            el.classList.add("active");
          }
        });

        // Update content
        if (t === "html") {
          els.output.value = els.layer.innerHTML
            .replace(/<\/div>/g, "</div>\n")
            .replace(/<br>/g, "<br>\n");
        } else if (t === "response") {
          // Render the AI Log
          let logContent = state.aiLog
            .map((entry, i) => {
              const status = entry.success ? "SUCCESS" : "ERROR";
              const rawResponse = entry.response
                ? JSON.stringify(entry.response, null, 2)
                : entry.response;

              const images = entry.request?.images;
              const requestStructure = entry.request?.structure || [];
              const score = entry.request?.score || "N/A";

              // Safely construct image HTML
              const targetImgHtml = images?.target
                ? `<img src="data:image/png;base64,${images.target}" style="width: 150px; height: auto; border: 2px solid #f97316; margin: 4px;" alt="Target Image Thumbnail" />`
                : `<div style="width: 150px; height: 100px; background: #374151; display: flex; align-items: center; justify-content: center; color: #fff; font-size: 0.75rem;">[No Target Image]</div>`;

              const renderImgHtml = images?.render
                ? `<img src="data:image/png;base64,${images.render}" style="width: 150px; height: auto; border: 2px solid #3b82f6; margin: 4px;" alt="Render Image Thumbnail" />`
                : `<div style="width: 150px; height: 100px; background: #374151; display: flex; align-items: center; justify-content: center; color: #fff; font-size: 0.75rem;">[No Render Image]</div>`;

              return `<div style="border-bottom: 1px solid #374151; padding-bottom: 1rem; margin-bottom: 1rem;">
                        <h4 style="font-weight: bold; color: ${entry.success ? "#9be658" : "#ef4444"};">--- Iteration ${entry.iter} (${entry.timestamp}) - ${status} ---</h4>
                        <div style="margin-top: 0.5rem; display: flex; gap: 1rem; align-items: flex-start; justify-content: space-around;">
                            <div style="text-align: center; font-family: monospace;">
                                Target:<br>
                                ${targetImgHtml}
                            </div>
                            <div style="text-align: center; font-family: monospace;">
                                Render:<br>
                                ${renderImgHtml}
                            </div>
                        </div>
                        <p style="color: #60a5fa; margin-top: 0.5rem; font-family: monospace;">Pre-Execution Delta Score: ${score}</p>
                        <pre style="white-space: pre-wrap; margin-top: 0.5rem; background: #111827; padding: 0.5rem; border-radius: 4px; color: #d1d5db; font-size: 0.75rem;">Request Structure: ${JSON.stringify(requestStructure, null, 2).substring(0, 300) + "..."}</pre>
                        <pre style="white-space: pre-wrap; background: #111827; padding: 0.5rem; border-radius: 4px; color: #9be658; font-size: 0.75rem;">Raw Response (Commands): ${rawResponse}</pre>
                    </div>`;
            })
            .join("");
          els.logView.innerHTML =
            logContent ||
            "<div style='font-family: monospace;'>// No AI responses yet.</div>";
        } else if (t === "prompt" || t === "payload") {
          els.logView.innerHTML = state.debug[t];
        }
      };

      els.output.addEventListener("input", () => {
        if (state.currTab === "html") {
          els.layer.innerHTML = els.output.value;
          renderMathInElement(els.layer, {
            delimiters: [{ left: "$$", right: "$$", display: true }],
          });
        }
      });

      // --- Core Logic ---

      /**
       * Captures the current styles and max vertical extent of the content block.
       * @param {string} divId - The ID of the container div (TEST_ID).
       * @returns {{elements: Array<object>, maxExtent: string}}
       */
      function getStructure(divId) {
        const div = document.getElementById(divId);
        if (!div) return { elements: [], maxExtent: "0.00" };

        // Ensure IDs
        Array.from(div.children).forEach((el, i) => {
          if (!el.id) el.id = `blk-${Date.now()}-${i}`;
        });

        let maxExtent = 0;

        const elements = Array.from(div.children)
          .filter((el) => el.innerText.trim().length > 0)
          .map((el) => {
            const computedStyle = window.getComputedStyle(el);
            const currentTop = parseFloat(el.style.top) || 0;
            const currentSize = parseFloat(el.style.fontSize) || 1.0;

            // Calculate current bottom edge for extent tracking
            const elementBottom = currentTop + currentSize;
            if (elementBottom > maxExtent) {
              maxExtent = elementBottom;
            }

            return {
              id: el.id,
              tag: el.tagName.toLowerCase(),
              text: el.innerText.substring(0, 30),
              currentStyles: {
                top: el.style.top || "0em",
                left: el.style.left || "0em",
                fontSize: el.style.fontSize || "1.0em",
                fontFamily: el.style.fontFamily || computedStyle.fontFamily,
                fontWeight: el.style.fontWeight || computedStyle.fontWeight,
              },
            };
          });

        return { elements, maxExtent: maxExtent.toFixed(2) };
      }

      function applyCommands(updates) {
        for (const [id, cmds] of Object.entries(updates)) {
          const el = document.getElementById(id);
          if (!el || !Array.isArray(cmds)) continue;

          el.style.position = "relative";
          let top = parseFloat(el.style.top) || 0;
          let left = parseFloat(el.style.left) || 0;
          let size = parseFloat(el.style.fontSize) || 1.0;

          cmds.forEach((c) => {
            const v = parseFloat(c.coefficient) || 0;
            if (c.action === "moveUp") top -= v;
            if (c.action === "moveDown") top += v;
            if (c.action === "moveLeft") left -= v;
            if (c.action === "moveRight") left += v;
            if (c.action === "grow") size += v;
            if (c.action === "shrink") size = Math.max(0.1, size - v);
            if (c.action === "setFontFamily" && c.value)
              el.style.fontFamily = String(c.value);
            if (c.action === "setFontWeight" && c.value)
              el.style.fontWeight = String(c.value);
            if (c.action === "setFontSize" && c.value) {
              const s = parseFloat(c.value);
              if (!isNaN(s)) el.style.fontSize = s.toFixed(2) + "em";
            }
          });

          el.style.top = top.toFixed(2) + "em";
          el.style.left = left.toFixed(2) + "em";
          el.style.fontSize = size.toFixed(2) + "em";
        }
        return updates;
      }

      /**
       * Generates a canvas showing blue pixels where targetCan text and htmlCan text overlap.
       */
      function createOverlapCanvas(targetCan, htmlCan) {
        const w = targetCan.width;
        const h = targetCan.height;
        const overlapCan = state.overlapCanvas;
        overlapCan.width = w;
        overlapCan.height = h;
        const overlapCtx = overlapCan.getContext("2d");

        // Clear canvas before drawing new data
        overlapCtx.clearRect(0, 0, w, h);

        const targetData = targetCan.getContext("2d").getImageData(0, 0, w, h);
        const htmlData = htmlCan.getContext("2d").getImageData(0, 0, w, h);
        const overlapData = overlapCtx.createImageData(w, h);

        // Thresholds to determine if a pixel is 'text' (dark). Text is usually dark, background is white.
        const COLOR_THRESHOLD = 120;
        const ALPHA_THRESHOLD = 100;
        const BLUE = [0, 0, 255, 255]; // RGBA blue

        for (let i = 0; i < targetData.data.length; i += 4) {
          // Target Text Check: Is the target pixel dark? (Assuming full opacity for target text)
          const avgTargetColor =
            (targetData.data[i] +
              targetData.data[i + 1] +
              targetData.data[i + 2]) /
            3;
          const isTargetText = avgTargetColor < COLOR_THRESHOLD;

          // HTML Render Text Check: Is the rendered text pixel opaque AND dark?
          // HTML2Canvas produces black text on transparent background (alpha = 0).
          const isHtmlText =
            htmlData.data[i + 3] > ALPHA_THRESHOLD && // Check opacity
            (htmlData.data[i] + htmlData.data[i + 1] + htmlData.data[i + 2]) /
              3 <
              COLOR_THRESHOLD;

          if (isTargetText && isHtmlText) {
            // Overlap detected: set pixel to Blue
            overlapData.data[i] = BLUE[0];
            overlapData.data[i + 1] = BLUE[1];
            overlapData.data[i + 2] = BLUE[2];
            overlapData.data[i + 3] = BLUE[3]; // Fully opaque
          }
        }

        overlapCtx.putImageData(overlapData, 0, 0);
        return overlapCan;
      }

      /**
       * Combines the static target image (bg), the HTML render, and the overlap overlay into one canvas.
       */
      function createCombinedRender(targetCan, htmlCan) {
        const rendCan = state.renderAI;
        rendCan.width = targetCan.width;
        rendCan.height = targetCan.height;
        const rendCtx = rendCan.getContext("2d");

        // 1. Draw the static target image (background + target text).
        rendCtx.drawImage(targetCan, 0, 0);

        // 2. Generate the overlap visualization (blue pixels)
        const overlapCan = createOverlapCanvas(targetCan, htmlCan);

        // 3. Draw the current HTML content (Render text). This is black text on transparent background.
        rendCtx.drawImage(htmlCan, 0, 0);

        // 4. Draw the overlap visualization. Use 'multiply' or 'source-over'
        // Using 'source-over' (default) ensures the blue replaces the existing black pixel where overlap is detected.
        // We need to ensure that the overlap layer is drawn on top of the black pixels of the rendered text.

        // To make the blue visible, we draw the overlap *last*.
        rendCtx.drawImage(overlapCan, 0, 0);

        return rendCan;
      }

      async function fetchWithBackoff(parts) {
        for (let attempt = 0; attempt < 5; attempt++) {
          try {
            const resp = await fetch(
              `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`,
              {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ contents: [{ role: "user", parts }] }),
              },
            );

            if (!resp.ok && resp.status === 429) {
              const delay = Math.pow(2, attempt) * 1000 + Math.random() * 1000;
              await new Promise((res) => setTimeout(res, delay));
              continue;
            }
            if (!resp.ok)
              throw new Error(
                `API error: ${resp.status} - ${await resp.text()}`,
              );

            const json = await resp.json();
            return json.candidates?.[0]?.content?.parts?.[0]?.text;
          } catch (e) {
            if (attempt === 4) throw e;
            await new Promise((res) =>
              setTimeout(res, Math.pow(2, attempt) * 1000),
            );
          }
        }
        throw new Error("API call failed after multiple retries.");
      }

      function cropAndScale(rect, scale, source) {
        const c = document.createElement("canvas");
        c.width = rect.w * scale;
        c.height = rect.h * scale;
        const ctx = c.getContext("2d");
        ctx.fillStyle = "#fff";
        ctx.fillRect(0, 0, c.width, c.height);
        ctx.drawImage(
          source,
          rect.x,
          rect.y,
          rect.w,
          rect.h,
          0,
          0,
          c.width,
          c.height,
        );
        return c;
      }

      function addBorder(canvas, color) {
        const c = document.createElement("canvas");
        c.width = canvas.width;
        c.height = canvas.height;
        const ctx = c.getContext("2d");
        ctx.drawImage(canvas, 0, 0);
        ctx.strokeStyle = color;
        ctx.lineWidth = 2;
        ctx.strokeRect(0, 0, c.width, c.height);
        return c;
      }

      function getRect(divId) {
        const div = document.getElementById(divId);
        if (!div) return null;
        const cw = state.viewCanvas.width,
          ch = state.viewCanvas.height;
        return {
          x: (parseFloat(div.style.left) / 100) * cw,
          y: (parseFloat(div.style.top) / 100) * ch,
          w: (parseFloat(div.style.width) / 100) * cw,
          h: (parseFloat(div.style.height) / 100) * ch,
        };
      }

      function drawCombinedRenderToView() {
        const rect = getRect(TEST_ID);
        if (!rect || !state.viewCtx || !img) return;
        const rendCan = state.renderAI;
        state.viewCtx.drawImage(
          img,
          0,
          0,
          state.viewCanvas.width,
          state.viewCanvas.height,
        );
        state.viewCtx.drawImage(
          rendCan,
          0,
          0,
          rendCan.width,
          rendCan.height,
          rect.x,
          rect.y,
          rect.w,
          rect.h,
        );
      }

      async function getDiff(b64A, b64B) {
        return new Promise((r) => {
          const i1 = new Image(),
            i2 = new Image();
          let c = 0;
          const onload = () => {
            if (++c === 2) diff();
          };
          i1.onload = onload;
          i2.onload = onload;
          i1.src = "data:image/png;base64," + b64A;
          i2.src = "data:image/png;base64," + b64B;
          function diff() {
            const cv = document.createElement("canvas");
            cv.width = i1.width;
            cv.height = i1.height;
            const cx = cv.getContext("2d");
            cx.drawImage(i1, 0, 0);
            const d1 = cx.getImageData(0, 0, cv.width, cv.height).data;
            cx.clearRect(0, 0, cv.width, cv.height);
            cx.drawImage(i2, 0, 0);
            const d2 = cx.getImageData(0, 0, cv.width, cv.height).data;
            let sum = 0;
            for (let k = 0; k < d1.length; k += 4)
              sum +=
                Math.abs(d1[k] - d2[k]) +
                Math.abs(d1[k + 1] - d2[k + 1]) +
                Math.abs(d1[k + 2] - d2[k + 2]);
            r(sum / (i1.width * i1.height * 765));
          }
        });
      }

      /**
       * Prepares the payload for the Gemini API call, including history, constraints, and the augmented structure.
       * @param {HTMLCanvasElement} targetCanvas - The target image canvas.
       * @param {HTMLCanvasElement} renderCanvas - The current render image canvas.
       * @param {string} iterLabel - The current iteration label.
       * @returns {{parts: Array<object>, payloadObj: object}}
       */
      function preparePayloadAndPrompt(targetCanvas, renderCanvas, iterLabel) {
        const divEl = document.getElementById(TEST_ID);
        if (!divEl) {
          return { parts: [{ text: "// Error: Content not found" }] };
        }

        // 1. Get Current Structure and Max Extent (Pre-Delta)
        const { elements: currentElements, maxExtent } = getStructure(TEST_ID);

        // --- DELTA CALCULATION & COMMAND INJECTION ---
        // We use the item at index 1 in history as the "previous" style baseline (State before last successful command execution).
        const previousHistoryForDelta = state.history[1];

        // We use the item at index 0 for the commands applied, as this led to the current state (or last saved state).
        const commandsFromPreviousRun = state.history[0]
          ? state.history[0].commands
          : {};

        let augmentedElements = currentElements;

        if (
          previousHistoryForDelta &&
          previousHistoryForDelta.structure &&
          previousHistoryForDelta.structure.elements
        ) {
          const previousElements = previousHistoryForDelta.structure.elements;

          augmentedElements = currentElements.map((currentEl) => {
            const prevEl = previousElements.find(
              (el) => el.id === currentEl.id,
            );

            const deltaStyles = {};

            if (prevEl) {
              const currentTop = parseFloat(currentEl.currentStyles.top);
              const prevTop = parseFloat(prevEl.currentStyles.top);
              deltaStyles.top = (currentTop - prevTop).toFixed(2) + "em";

              const currentLeft = parseFloat(currentEl.currentStyles.left);
              const prevLeft = parseFloat(prevEl.currentStyles.left);
              deltaStyles.left = (currentLeft - prevLeft).toFixed(2) + "em";

              const currentSize = parseFloat(currentEl.currentStyles.fontSize);
              const prevSize = parseFloat(prevEl.currentStyles.fontSize);
              deltaStyles.fontSize = (currentSize - prevSize).toFixed(2) + "em";
            }

            // If no previous state found (e.g., element ID mismatch or first two runs), delta is 0
            const commandsAppliedToThisElement =
              commandsFromPreviousRun[currentEl.id] || [];

            return {
              ...currentEl,
              deltaStyles: prevEl
                ? deltaStyles
                : { top: "0.00em", left: "0.00em", fontSize: "0.00em" },
              // Inject the commands that resulted in the state of the comparison frame
              commandsAppliedInLastStep: commandsAppliedToThisElement,
            };
          });
        }

        // 2. Build Constraint Warning
        const maxLimit = state.MAX_VERTICAL_EM.toFixed(2);
        let constraintWarning = `\n\n***********************************\n`;
        constraintWarning += `*** WARNING: VERTICAL CONSTRAINT ***\n`;
        constraintWarning += `MAXIMUM vertical extent allowed for all content is ${maxLimit}em.\n`;
        constraintWarning += `CURRENT vertical extent (bottom edge of lowest element) is ${maxExtent}em.\n`;

        if (parseFloat(maxExtent) >= parseFloat(maxLimit)) {
          constraintWarning += `ACTION REQUIRED: Current extent is at or over the limit. Avoid 'moveDown' or 'grow' actions. Consider 'shrink' or 'moveUp'.\n`;
        } else {
          const remaining = (
            parseFloat(maxLimit) - parseFloat(maxExtent)
          ).toFixed(2);
          constraintWarning += `Space remaining: ${remaining}em. Proceed with caution.\n`;
        }
        constraintWarning += `***********************************\n\n`;

        // Replace the structure placeholder with the augmented structure
        let promptTemplateText = state.promptTemplate.replace(
          "{{structure}}",
          JSON.stringify(augmentedElements, null, 2),
        );

        // Inject the warning into the prompt text before the structure
        const textPromptBase = constraintWarning + promptTemplateText;

        // --- Prepare Payload Parts (Interleaved) ---
        const parts = [];
        let debugVisualPrompt = ""; // For "Prompt Text" tab

        // 3. History (if any)
        // Slice last 3, reverse to show chronological order: [Step -3, Step -2, Step -1]
        // This is the chronological array used for the API parts array
        const chronologicalHistory = state.history.slice(0, 3).reverse();

        if (chronologicalHistory.length > 0) {
          parts.push({
            text: "### HISTORY OF RECENT ACTIONS (Oldest to Newest):\n",
          });
          debugVisualPrompt +=
            "<h3>### HISTORY OF RECENT ACTIONS (Oldest to Newest):</h3>";

          chronologicalHistory.forEach((h, i) => {
            // Iteration number logic
            const currentRun = parseInt(iterLabel.match(/\d+/)?.[0] || "1", 10);
            // Calculate the true historical step number
            const stepNum = currentRun - (state.history.length - i);

            const stepText = `\n--- Step ${Math.max(0, stepNum)} ---\nDelta Score (Pre-Command): ${h.score}\nCommands Executed: ${JSON.stringify(h.commands)}\nRESULTING FRAME (below):`;

            parts.push({ text: stepText });
            parts.push({
              inlineData: { mimeType: "image/png", data: h.resultImage },
            }); // PNG Thumbnail is here!

            // Update Debug Visual HTML
            debugVisualPrompt += `
                <div style="border: 1px solid #555; padding: 10px; margin-bottom: 10px; background: #222;">
                    <div style="font-family: monospace; color: #aaa; white-space: pre-wrap;">${stepText}</div>
                    <img src="data:image/png;base64,${h.resultImage}" style="width: 150px; border: 1px solid #777; margin-top: 5px;" />
                </div>`;
          });
          parts.push({ text: "\n----------------\n" });
          debugVisualPrompt +=
            "<hr style='border-color: #444; margin: 15px 0;' />";
        } else {
          parts.push({
            text: "(No history available yet. This is the first step.)\n",
          });
          debugVisualPrompt +=
            "<p style='color: #666; font-style: italic;'>(No history available yet)</p>";
        }

        // 4. Current Context
        const borderedTarget = addBorder(targetCanvas, "#f00");
        const borderedRender = addBorder(renderCanvas, "#3b82f6");
        const targetBase64 = borderedTarget.toDataURL().split(",")[1];
        const renderBase64 = borderedRender.toDataURL().split(",")[1];

        // The warning and prompt template text goes first
        parts.push({
          text:
            textPromptBase +
            "\n\n--- VISUAL INPUTS ---\n1. TARGET (Red Border):\n",
        });
        parts.push({
          inlineData: { mimeType: "image/png", data: targetBase64 },
        });

        parts.push({ text: "\n2. CURRENT RENDER (Blue Border):\n" });
        parts.push({
          inlineData: { mimeType: "image/png", data: renderBase64 },
        });

        // Update Debug Visual HTML (Current Task)
        debugVisualPrompt += `
        <div style="background: #1f2937; padding: 15px; border-radius: 8px; border: 1px solid #374151;">
            <h3 style="color: #ddd; margin-bottom: 10px;">CURRENT TASK INPUTS</h3>
            <div style="display: flex; gap: 20px; margin-bottom: 15px;">
                <div>
                    <div style="color: #f87171; font-weight: bold; font-size: 0.8em; margin-bottom: 4px;">TARGET</div>
                    <img src="data:image/png;base64,${targetBase64}" style="width: 150px; border: 2px solid #ef4444;" />
                </div>
                <div>
                    <div style="color: #60a5fa; font-weight: bold; font-size: 0.8em; margin-bottom: 4px;">RENDER</div>
                    <img src="data:image/png;base64,${renderBase64}" style="width: 150px; border: 2px solid #3b82f6;" />
                </div>
            </div>
            <pre style="font-family: monospace; color: #9ca3af; font-size: 0.8em; white-space: pre-wrap;">${textPromptBase}</pre>
        </div>`;

        state.debug.prompt = debugVisualPrompt;

        // --- Payload Object for "Full Payload" Tab ---
        // Use the chronological array for the debug object to ensure correct order
        const fullPayloadData = {
          iter: iterLabel || "Initial",
          partsCount: parts.length,
          currentScore: "Calculated Pre-Execution",
          constraint: { maxLimit, currentExtent: maxExtent },
          currentImages: {
            target: targetBase64,
            render: renderBase64,
          },
          structure: augmentedElements,
          history: chronologicalHistory.map((h, i) => {
            const currentRun = parseInt(iterLabel.match(/\d+/)?.[0] || "1", 10);
            const step = currentRun - (state.history.length - i);
            return {
              step: Math.max(0, step),
              score: h.score,
              commands: h.commands,
              resultImage: h.resultImage,
            };
          }),
        };
        const payloadJsonText = JSON.stringify(
          fullPayloadData,
          (key, value) => {
            if (
              typeof value === "string" &&
              value.length > 500 &&
              key.toLowerCase().includes("image")
            ) {
              // Truncate Base64 in JSON for cleaner text view, the HTML will use the full string
              return (
                value.substring(0, 50) + `... [${value.length} chars truncated]`
              );
            }
            return value;
          },
          2,
        );

        // --- Full Payload HTML Generation ---
        let historyHtml = fullPayloadData.history
          .map((h, i) => {
            const base64Id = `hist-b64-${h.step}`;
            const commandsText = JSON.stringify(h.commands, null, 2);
            return `
    <div class="border border-gray-700 p-3 rounded-lg mb-4 bg-gray-800">
        <h5 class="text-sm font-bold text-yellow-400">History Step ${h.step} (Score: ${h.score})</h5>
        <div class="flex flex-col md:flex-row md:items-start gap-4 mt-2">
            <div>
                <img src="data:image/png;base64,${h.resultImage}" class="image-thumbnail-payload border-yellow-400" alt="Result Frame" />
            </div>
            <div class="flex-1">
                <p class="text-xs text-gray-300 mb-1">Commands Executed:</p>
                <pre class="bg-gray-900 p-2 text-xs text-green-400 rounded overflow-x-auto">${commandsText}</pre>
                <div class="base64-container mt-2">
                    <span class="base64-toggle-span" onclick="window.toggleBase64('${base64Id}')">Toggle Result Image Base64 (Full)</span>
                    <div id="${base64Id}" class="base64-full">${h.resultImage}</div>
                </div>
            </div>
        </div>
    </div>`;
          })
          .join("");

        const targetB64Id = "target-b64";
        const renderB64Id = "render-b64";

        state.debug.payload = `
<div style="margin-bottom: 15px; color: #f87171;">
    // This tab shows the complete data (visuals & metadata) being analyzed.
</div>

<h4 class="font-bold text-lg text-purple-400 border-b border-gray-700 pb-2 mb-4">Current Visual Context</h4>
<div class="flex gap-8 mb-6">
    <div>
        <h5 class="text-sm font-bold text-red-400">Target Image (Red Border)</h5>
        <img src="data:image/png;base64,${fullPayloadData.currentImages.target}" class="image-thumbnail-payload border-red-400" alt="Target Image" />
        <div class="base64-container mt-2">
            <span class="base64-toggle-span" onclick="window.toggleBase64('${targetB64Id}')">Toggle Base64 (Full)</span>
            <div id="${targetB64Id}" class="base64-full">${fullPayloadData.currentImages.target}</div>
        </div>
    </div>
    <div>
        <h5 class="text-sm font-bold text-blue-400">Current Render (Blue Border)</h5>
        <img src="data:image/png;base64,${fullPayloadData.currentImages.render}" class="image-thumbnail-payload border-blue-400" alt="Current Render" />
        <div class="base64-container mt-2">
            <span class="base64-toggle-span" onclick="window.toggleBase64('${renderB64Id}')">Toggle Base64 (Full)</span>
            <div id="${renderB64Id}" class="base64-full">${fullPayloadData.currentImages.render}</div>
        </div>
    </div>
</div>

<h4 class="font-bold text-lg text-purple-400 border-b border-gray-700 pb-2 mb-4">Historical Frames and Commands</h4>
${historyHtml}

<h4 class="font-bold text-lg text-purple-400 border-b border-gray-700 pb-2 mt-4">API Metadata JSON (Truncated Images in Text)</h4>
<pre class="bg-gray-900 p-4 text-xs text-d1d5db rounded overflow-x-auto">${payloadJsonText}</pre>
        `;

        return { parts, payloadObj: fullPayloadData };
      }

      /**
       * Captures images (Target and Render) using a specific scale.
       * @param {HTMLImageElement} originalImage - The full background image.
       * @param {boolean} isInitialRun - Whether to set the fixed state.targetAI image.
       * @param {string} iterLabel - The current iteration label for logging/debugging.
       * @param {number} scale - The image capture scale (0.5 or 2.0).
       * @returns {Promise<void>}
       */
      async function updateAIImagesAndPayload(
        originalImage,
        isInitialRun,
        iterLabel,
        scale,
      ) {
        const divEl = document.getElementById(TEST_ID);
        if (!divEl) return;
        const rect = getRect(TEST_ID);

        // NOTE: The Target image (state.targetAI) is only set on initial run, and should use DEFAULT_AI_SCALE (0.5)
        if (isInitialRun) {
          const srcCan = cropAndScale(rect, DEFAULT_AI_SCALE, originalImage);
          state.targetAI.width = srcCan.width;
          state.targetAI.height = srcCan.height;
          state.targetAI.getContext("2d").drawImage(srcCan, 0, 0);
        }

        // Must capture the HTML layer using the current run's desired scale
        const htmlLayerCan = await html2canvas(divEl, {
          scale: scale, // Use dynamic scale
          backgroundColor: null,
          width: rect.w,
          height: rect.h,
        });

        // Create the combined render. Note: targetCan uses DEFAULT_AI_SCALE, htmlCan uses current scale.
        // We must resize the target image to match the current HTML capture scale for combination.

        // 1. Resize Target to match current scale (if different from 0.5)
        let scaledTargetCan = state.targetAI;
        if (scale !== DEFAULT_AI_SCALE) {
          scaledTargetCan = cropAndScale(rect, scale, originalImage);
        }

        const renderCan = createCombinedRender(scaledTargetCan, htmlLayerCan);

        // Final payload preparation uses the images we just created (which are either 0.5 or 2.0 scale)
        preparePayloadAndPrompt(scaledTargetCan, renderCan, iterLabel);

        // *** FIX/NEW: Save initial state (Run 0) to history for delta baseline ***
        if (isInitialRun) {
          const resultB64 = renderCan.toDataURL().split(",")[1];
          const { elements: initialElements, maxExtent: initialExtent } =
            getStructure(TEST_ID);

          // Check if history is already initialized to prevent duplicate Run 0 entries on reloads
          if (
            state.history.length === 0 ||
            state.history[state.history.length - 1].commands !== null
          ) {
            state.history.unshift({
              score: "0.00%",
              commands: {},
              resultImage: resultB64,
              structure: {
                elements: initialElements,
                maxExtent: initialExtent,
              },
            });
            console.log(
              "Initial state (Run 0) saved to history for delta baseline.",
            );
          }
        }
      }

      /**
       * Executes a single iteration of the AI loop.
       * @param {number} i - Current iteration number (1-indexed).
       * @param {number} max - Total number of iterations.
       */
      async function runIteration(i, max) {
        const divEl = document.getElementById(TEST_ID);
        if (!divEl) return;

        const iter = `Run ${i}/${max}`;

        // Determine scale for this run: 2.0 only for the final iteration, 0.5 otherwise.
        currentRunScale = i === max ? FINAL_AI_SCALE : DEFAULT_AI_SCALE;

        els.status.textContent = `${iter} Capturing... (Scale: ${currentRunScale})`;
        els.status.style.display = "inline";

        // 1. Pre-Run Capture - This captures images at the determined scale (0.5 or 2.0)
        // Note: The payloadObj prepared here will include images scaled to currentRunScale.
        await updateAIImagesAndPayload(img, false, iter, currentRunScale);

        const srcCan = state.targetAI;
        const rendCan = state.renderAI;

        // NOTE: Delta calculation uses the captured images (which may be 2.0 scale on final run)
        const srcB64 = srcCan.toDataURL().split(",")[1];
        const rendB64 = rendCan.toDataURL().split(",")[1];
        const deltaScore = await getDiff(srcB64, rendB64);
        const scoreString = (deltaScore * 100).toFixed(2) + "%";

        // Retrieve payload (now contains delta)
        const { parts, payloadObj } = preparePayloadAndPrompt(
          srcCan,
          rendCan,
          iter,
        );
        payloadObj.score = scoreString;

        if (state.currTab !== "html") window.setTab(state.currTab);

        els.status.textContent = `${iter} Thinking... (Scale: ${currentRunScale})`;
        let logEntry = {
          iter,
          success: false,
          request: payloadObj,
          response: "Error/No response",
          timestamp: new Date().toLocaleTimeString(),
        };

        try {
          const resultJsonStr = await fetchWithBackoff(parts);
          if (!resultJsonStr) throw new Error("Empty response from AI.");

          const jsonMatch = resultJsonStr.match(/\{[\s\S]*\}/);
          const updates = JSON.parse(jsonMatch ? jsonMatch[0] : "{}");

          logEntry.response = updates;
          logEntry.success = true;

          const appliedCommands = applyCommands(updates);

          // *** CRITICAL STEP: Recapture POST-APPLY state for history ***
          // Recapture HTML content. We must recapture at DEFAULT_AI_SCALE (0.5) to store in history.
          // The history array is always saved at the low resolution to keep payload size down.
          await updateAIImagesAndPayload(
            img,
            false,
            `${iter} (Post-Apply)`,
            DEFAULT_AI_SCALE,
          );
          const resultB64 = state.renderAI.toDataURL().split(",")[1]; // Capture combined result at 0.5 scale

          // Get the structure *after* commands were applied
          const {
            elements: postCommandElements,
            maxExtent: postCommandExtent,
          } = getStructure(TEST_ID);

          // Store: Pre-Score, Commands executed, Result Image, and *POST-COMMAND* structure
          state.history.unshift({
            score: scoreString,
            commands: appliedCommands,
            resultImage: resultB64, // Saved at 0.5 scale
            structure: {
              elements: postCommandElements,
              maxExtent: postCommandExtent,
            }, // Save the resulting structure
          });

          console.log(
            `Applied ${Object.keys(appliedCommands).length} updates. Score: ${scoreString}`,
          );

          // We must now re-run updateAIImagesAndPayload to set up the visualization
          // for the next step, using the *currentRunScale* (which might be the final 2.0 scale)
          await updateAIImagesAndPayload(
            img,
            false,
            `Pre-Run ${i + 1}/${max}`,
            currentRunScale,
          );

          // Draw to view (uses the frame set by the previous line)
          drawCombinedRenderToView();

          // Update editor
          els.output.value = els.layer.innerHTML
            .replace(/<\/div>/g, "</div>\n")
            .replace(/<br>/g, "<br>\n");
          if (state.currTab === "html") window.setTab("html");
        } catch (e) {
          logEntry.response = `Error: ${e.message}`;
          console.error(e);
        } finally {
          state.aiLog.unshift(logEntry);
          if (state.currTab === "response") window.setTab("response");

          // Ensure the view is updated to the latest rendered state.
          await updateAIImagesAndPayload(
            img,
            false,
            `Pre-Run ${i + 1}/${max}`,
            currentRunScale,
          );
          drawCombinedRenderToView();
        }
      }

      els.runBtn.onclick = async () => {
        els.runBtn.disabled = true;
        state.history = []; // Reset history at the start of a new run sequence

        // Re-add initial state to history for a fresh run sequence (at 0.5 scale)
        await updateAIImagesAndPayload(
          img,
          true,
          "Initial Baseline Reset",
          DEFAULT_AI_SCALE,
        );

        const max = parseInt(els.loopInput.value);
        for (let i = 1; i <= max; i++) await runIteration(i, max);

        // Set final view based on the last run (which was at FINAL_AI_SCALE)
        els.layer.innerHTML = els.output.value;
        drawCombinedRenderToView();
        els.status.style.display = "none";
        els.runBtn.disabled = false;
        window.setTab("html");
      };

      els.output.value = INITIAL_HTML.replace(/<\/div>/g, "</div>\n").replace(
        /<br>/g,
        "<br>\n",
      );
      els.layer.innerHTML = INITIAL_HTML;
      window.setTab("html");
      renderMathInElement(els.layer, {
        delimiters: [{ left: "$$", right: "$$", display: true }],
      });

      img = new Image();
      img.crossOrigin = "anonymous";
      img.onload = async () => {
        state.viewCanvas.width = img.width;
        state.viewCanvas.height = img.height;
        els.wrapper.style.width = state.viewCanvas.width + "px";
        els.wrapper.style.height = state.viewCanvas.height + "px";
        state.viewCtx = state.viewCanvas.getContext("2d");
        state.viewCtx.drawImage(
          img,
          0,
          0,
          state.viewCanvas.width,
          state.viewCanvas.height,
        );

        // 1. Setup Target and Initial Render Canvases (at 0.5 scale)
        await updateAIImagesAndPayload(img, true, "Initial", DEFAULT_AI_SCALE);

        // 2. Draw initial frame to view
        drawCombinedRenderToView();
      };
      img.src = SAMPLE_URL;
    </script>
  </body>
</html>
